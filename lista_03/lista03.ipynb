{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaração de funções custo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from typing import Literal\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import NDArray\n",
    "from IPython.display import display\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_euclidean(x1: NDArray, x2: NDArray):\n",
    "    return np.linalg.norm(x1 - x2, axis=1)\n",
    "\n",
    "def distance_mahalanobis(x1, x2, inv_cov):\n",
    "    diff = x1 - x2\n",
    "    return np.sqrt(np.diag(diff @ inv_cov @ diff.T))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular métricas de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(y_test: NDArray, y_predict: NDArray):\n",
    "    y_test = y_test[:, 0]\n",
    "    n = y_test.shape[0]\n",
    "\n",
    "    TP = np.sum(np.logical_and(y_predict == y_test, y_test == 1))\n",
    "    TN = np.sum(np.logical_and(y_predict == y_test, y_test == 0))\n",
    "    FP = np.sum(np.logical_and(y_predict == 1, y_test == 0))\n",
    "    FN = np.sum(np.logical_and(y_predict == 0, y_test == 1))\n",
    "\n",
    "    accuracy = (TP + TN) / n\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaração dos escaladores MinMax e ZScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler(ABC):\n",
    "    @abstractmethod\n",
    "    def normalize(self, X: NDArray, update_params: bool = False) -> NDArray:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def denormalize(self, X: NDArray) -> NDArray:\n",
    "        pass\n",
    "\n",
    "class ZScore(Scaler):\n",
    "    def __init__(self):\n",
    "        self.mean: NDArray = None\n",
    "        self.std: NDArray = None\n",
    "        pass\n",
    "\n",
    "    def normalize(self, X: NDArray, update_params: bool = False):\n",
    "        mean = np.mean(X, axis=0) if self.mean is None or update_params else self.mean\n",
    "        std = np.std(X, axis=0) if self.std is None or update_params else self.std\n",
    "\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "        return (X - mean) / std\n",
    "\n",
    "    def denormalize(self, X: NDArray):\n",
    "        return X * self.std + self.mean\n",
    "\n",
    "class MinMax(Scaler):\n",
    "    def __init__(self):\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "        pass\n",
    "\n",
    "    def normalize(self, X: NDArray, update_params: bool = False):\n",
    "        min = np.min(X, axis=0) if self.min is None or update_params else self.min\n",
    "        max = np.max(X, axis=0) if self.max is None or update_params else self.max\n",
    "\n",
    "        self.min = min\n",
    "        self.max = max\n",
    "\n",
    "        return (X - min) / (max - min)\n",
    "\n",
    "    def denormalize(self, X: NDArray):\n",
    "        return X * (self.max - self.min) + self.min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementação do KNN com a mesma interface do modelo do scikit learn para usar na validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(ABC):\n",
    "    has_training_costs = False\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X: NDArray, y: NDArray):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X: NDArray) -> NDArray:\n",
    "        pass\n",
    "\n",
    "\n",
    "class KNN(Model):\n",
    "    def __init__(self, k: int, distance_function: Literal['euclidean', 'mahalanobis'] = 'euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_function = distance_function\n",
    "        self.in_scaler = ZScore()\n",
    "\n",
    "    def fit(self, X: NDArray, y: NDArray):\n",
    "        X = self._preprocess_input(X, True)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        if self.distance_function == 'mahalanobis':\n",
    "            cov = np.cov(X.T, bias=True)\n",
    "            self.inv_cov = np.linalg.pinv(cov)\n",
    "\n",
    "    def predict(self, X: NDArray):\n",
    "        X = self._preprocess_input(X, False)\n",
    "        n, m = X.shape\n",
    "        y_predict = np.zeros(n)\n",
    "        for i, x in enumerate(X):\n",
    "            distances = self._get_distances(x)\n",
    "            k_neighbors = np.argpartition(distances, self.k)[:self.k]\n",
    "            y_predict[i] = np.bincount(self.y[k_neighbors].ravel()).argmax()\n",
    "\n",
    "        return y_predict\n",
    "\n",
    "    def _preprocess_input(self, X: NDArray, update_params: bool = False):\n",
    "        n, m = X.shape\n",
    "        X_normalized = self.in_scaler.normalize(X, update_params)\n",
    "        return X_normalized\n",
    "\n",
    "    def _get_distances(self, x: NDArray):\n",
    "        match self.distance_function:\n",
    "            case 'euclidean':\n",
    "                return distance_euclidean(self.X, x)\n",
    "            case 'mahalanobis':\n",
    "                return distance_mahalanobis(self.X, x, self.inv_cov)\n",
    "            case _:\n",
    "                raise ValueError(f'Unknown distance function: {self.distance_function}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes para treinar vários modelos usando validação cruzada (K-Folds) e Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldTrainer:\n",
    "    '''\n",
    "    Treina um modelo (instanciado com hyper parâmetros), separando k partições de treino/validação\n",
    "    Salva a média das métricas de cada validação feita\n",
    "    '''\n",
    "    def __init__(self, k: int, n_classes: int, dataset: NDArray, model: Model):\n",
    "        self.k = k\n",
    "        self.n_classes = n_classes\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.metrics = None\n",
    "\n",
    "    def fit(self):\n",
    "        metrics = {\n",
    "            'accuracy': np.zeros(self.k),\n",
    "            'precision': np.zeros(self.k),\n",
    "            'recall': np.zeros(self.k),\n",
    "            'f1_score': np.zeros(self.k),\n",
    "        }\n",
    "        for i, dataset in enumerate(self._genereate_dataset_k_folds()):\n",
    "            X_train, y_train, X_validation, y_validation = dataset\n",
    "            self.model.fit(X_train, y_train)\n",
    "\n",
    "            y_predict = self.model.predict(X_validation)\n",
    "            metrics_i = evaluate_metrics(y_validation, y_predict)\n",
    "            for key, value in metrics_i.items():\n",
    "                metrics[key][i] = value\n",
    "\n",
    "        self.metrics = {\n",
    "            key: np.mean(value)\n",
    "            for key, value in metrics.items()\n",
    "        }\n",
    "\n",
    "    def _genereate_dataset_k_folds(self):\n",
    "        np.random.shuffle(self.dataset)\n",
    "        X, y = self.dataset[:, :-1], self.dataset[:, -1].astype(int).reshape((-1, 1))\n",
    "        validation_size_percent = 1 / self.k\n",
    "\n",
    "        n, _ = X.shape\n",
    "        validation_size = ceil(n * validation_size_percent)\n",
    "        for i in range(self.k):\n",
    "            validation_index_start = i * validation_size\n",
    "            validation_index_final = (i + 1) * validation_size if i < self.k - 1 else n\n",
    "\n",
    "            X_validation = X[validation_index_start:validation_index_final]\n",
    "            y_validation = y[validation_index_start:validation_index_final]\n",
    "            X_train = np.concatenate([X[:validation_index_start], X[validation_index_final:]])\n",
    "            y_train = np.concatenate([y[:validation_index_start], y[validation_index_final:]])\n",
    "\n",
    "            yield X_train, y_train, X_validation, y_validation\n",
    "\n",
    "class GridSearchTrainer:\n",
    "    '''\n",
    "    Instancia um modelo a partir de sua classe com cada combinação possível dos hyper parâmetros recebidos\n",
    "    Chama o KFoldTrainer para fazer a validação cruzada para cada combinação de hyper parâmetros\n",
    "    Salva as métricas, modelo (treinado), e hyper parâmetros escolhidos da melhor combinação encontrada (avaliado pela acurácia)\n",
    "    '''\n",
    "    def __init__(self, k: int, n_classes: int, dataset: NDArray, model_class: type[Model], hyper_params: dict[str, list]):\n",
    "        self.k = k\n",
    "        self.n_classes = n_classes\n",
    "        self.dataset = dataset\n",
    "        self.model_class = model_class\n",
    "        self.hyper_params = hyper_params\n",
    "        self.best_model = None\n",
    "        self.best_hyper_params = None\n",
    "        self.best_metrics = None\n",
    "\n",
    "    def fit(self):\n",
    "        params_names = list(self.hyper_params.keys())\n",
    "        grid = np.meshgrid(*self.hyper_params.values())\n",
    "        grid = np.hstack([ np.atleast_2d(g.ravel()).T for g in grid ], dtype='object')\n",
    "\n",
    "        best_metrics = None\n",
    "        best_model = None\n",
    "        best_hyper_params = None\n",
    "        for params in grid:\n",
    "            params = dict(zip(params_names, params))\n",
    "            model = self.model_class(**params)\n",
    "\n",
    "            k_fold_trainer = KFoldTrainer(self.k, self.n_classes, self.dataset, model)\n",
    "            k_fold_trainer.fit()\n",
    "            accuracy = k_fold_trainer.metrics['accuracy']\n",
    "\n",
    "            if best_model is None or accuracy > best_metrics['accuracy']:\n",
    "                best_metrics = k_fold_trainer.metrics\n",
    "                best_model = model\n",
    "                best_hyper_params = params\n",
    "\n",
    "        self.best_model = best_model\n",
    "        self.best_hyper_params = best_hyper_params\n",
    "        self.best_metrics = best_metrics\n",
    "\n",
    "\n",
    "class KFoldMultiModelsTrainer(KFoldTrainer):\n",
    "    '''\n",
    "    Treina vários modelos separando o dataset em k partições de treinamento/teste para fazer validações cruzadas\n",
    "    Chama o GridSearchTrainer para encontrar a melhor combinação de hyper parâmetros de um modelo, para cada conjunto de treinamento\n",
    "    Para cada modelo, salva a média e o desvio padrão das métricas com a melhor combinação de hyper parâmetros para cada conjunto de treinamento\n",
    "    '''\n",
    "    def __init__(self, k: int, n_classes: int, dataset: NDArray, models: dict[str, tuple[type[Model], dict[str, list]]]):\n",
    "        self.k = k\n",
    "        self.n_classes = n_classes\n",
    "        self.dataset = dataset\n",
    "        self.models = models\n",
    "\n",
    "    def fit(self):\n",
    "        trained_models = dict()\n",
    "        for model_name, value in self.models.items():\n",
    "            model_class, hyper_params = value\n",
    "            model_attributes = {\n",
    "                'metrics_train': {\n",
    "                    metric: np.zeros(self.k)\n",
    "                    for metric in ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "                },\n",
    "                'metrics_test': {\n",
    "                    metric: np.zeros(self.k)\n",
    "                    for metric in ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "                },\n",
    "                'hyper_params': {\n",
    "                    param: np.zeros(self.k, dtype=np.object_)\n",
    "                    for param in hyper_params.keys()\n",
    "                },\n",
    "                'model': np.zeros(self.k, dtype=np.object_)\n",
    "            }\n",
    "            for i, dataset in enumerate(self._genereate_dataset_k_folds()):\n",
    "                X_train, y_train, X_test, y_test = dataset\n",
    "                dataset_train = np.c_[X_train, y_train]\n",
    "                trainer = GridSearchTrainer(self.k, self.n_classes, dataset_train, model_class, hyper_params)\n",
    "                trainer.fit()\n",
    "                y_predict = trainer.best_model.predict(X_test)\n",
    "                test_metrics = evaluate_metrics(y_test, y_predict)\n",
    "\n",
    "                for metric in model_attributes['metrics_train'].keys():\n",
    "                    model_attributes['metrics_train'][metric][i] = trainer.best_metrics[metric]\n",
    "                    model_attributes['metrics_test'][metric][i] = test_metrics[metric]\n",
    "\n",
    "                for param in model_attributes['hyper_params'].keys():\n",
    "                    model_attributes['hyper_params'][param][i] = trainer.best_hyper_params[param]\n",
    "\n",
    "                model_attributes['model'][i] = trainer.best_model\n",
    "\n",
    "            trained_models[model_name] = model_attributes\n",
    "\n",
    "        return trained_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_costs(costs: NDArray, title: str):\n",
    "    plt.plot(costs)\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Cross Entropia')\n",
    "    plt.title(f'Função Custo {title}')\n",
    "    plt.show()\n",
    "\n",
    "def extract_from_text(text: str):\n",
    "        return float(text.split('%')[0])\n",
    "\n",
    "def plot_models_metrics(trained_models: dict[str, dict[str, list[float]]]):\n",
    "    table = pd.DataFrame(trained_models).T.map(lambda x: f\"{np.mean(x):.2%} +- {1.96*np.std(x)/np.sqrt(len(x)):.2%}\")\n",
    "    table.columns = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "    table.index = trained_models.keys()\n",
    "\n",
    "    styled_table = table.style.apply(lambda col: [ 'font-weight:bold; color:red' if extract_from_text(x)==col.apply(extract_from_text).max() else '' for x in col ])\n",
    "    display(styled_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 01 -> Items a,b\n",
    "\n",
    "1. Lendo o dataset 'kc2.csv'\n",
    "1. Treinando o modelo KNN implementado e a Árvores de Decisão do scikit-learn com o dataset\n",
    "1. Definindo os possíveis valores dos hyper parâmetros para o grid search\n",
    "1. Treinando modelos usando 10 partições para testes cruzados, e 10 partições para validações cruzadas\n",
    "1. Plot da média e desvio padrão das métricas de cada modelo com a melhor combinação de hiper parâmetros encontrados em treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b41c4_row0_col0, #T_b41c4_row0_col1, #T_b41c4_row0_col2, #T_b41c4_row0_col3 {\n",
       "  font-weight: bold;\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b41c4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b41c4_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_b41c4_level0_col1\" class=\"col_heading level0 col1\" >Precision</th>\n",
       "      <th id=\"T_b41c4_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_b41c4_level0_col3\" class=\"col_heading level0 col3\" >F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b41c4_level0_row0\" class=\"row_heading level0 row0\" >KNN</th>\n",
       "      <td id=\"T_b41c4_row0_col0\" class=\"data row0 col0\" >75.51% +- 2.52%</td>\n",
       "      <td id=\"T_b41c4_row0_col1\" class=\"data row0 col1\" >75.64% +- 7.12%</td>\n",
       "      <td id=\"T_b41c4_row0_col2\" class=\"data row0 col2\" >75.07% +- 4.60%</td>\n",
       "      <td id=\"T_b41c4_row0_col3\" class=\"data row0 col3\" >74.54% +- 3.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b41c4_level0_row1\" class=\"row_heading level0 row1\" >Árvode de Decisão</th>\n",
       "      <td id=\"T_b41c4_row1_col0\" class=\"data row1 col0\" >72.16% +- 5.77%</td>\n",
       "      <td id=\"T_b41c4_row1_col1\" class=\"data row1 col1\" >71.33% +- 9.22%</td>\n",
       "      <td id=\"T_b41c4_row1_col2\" class=\"data row1 col2\" >73.44% +- 9.53%</td>\n",
       "      <td id=\"T_b41c4_row1_col3\" class=\"data row1 col3\" >71.35% +- 7.37%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x79cb114c74d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = np.genfromtxt('kc2.csv', delimiter=',')\n",
    "\n",
    "k = 10\n",
    "n_classes = 2\n",
    "np.random.seed(0)\n",
    "models = {\n",
    "    'KNN': (KNN, {'k': [1, 5], 'distance_function': ['euclidean', 'mahalanobis']}),\n",
    "    'Árvode de Decisão': (DecisionTreeClassifier, {'criterion': ['gini', 'entropy']}),\n",
    "}\n",
    "trainer = KFoldMultiModelsTrainer(k, n_classes, dataset, models)\n",
    "\n",
    "trained_models = trainer.fit()\n",
    "trained_models_metrics = {\n",
    "    name: results['metrics_test']\n",
    "    for name, results in trained_models.items()\n",
    "}\n",
    "plot_models_metrics(trained_models_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
